{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../.env.local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd47f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"API_KEY: {my_api_key}\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = my_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"PLease ask a question\")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"Bye Bye\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"add '{user_input}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a93de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = my_api_key\n",
    "print (client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85860191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Cz67Nf27Z0a9VVKahJfoC8YfT5Xeq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='SOS is the international distress signal used to request urgent help. In Morse code it is ...---... (three dots, three dashes, three dots). It\\'s not an official acronym, though popular backronyms include \"Save Our Souls\" or \"Save Our Ship.\" It originated as a simple, easy-to-recognize signal for emergencies at sea and is still used in maritime, aviation, and other urgent situations. Want more details or examples?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1768677561, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=612, prompt_tokens=27, total_tokens=639, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=512, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "THIS THE NEXTLINE ==============\n",
      "SOS is the international distress signal used to request urgent help. In Morse code it is ...---... (three dots, three dashes, three dots). It's not an official acronym, though popular backronyms include \"Save Our Souls\" or \"Save Our Ship.\" It originated as a simple, easy-to-recognize signal for emergencies at sea and is still used in maritime, aviation, and other urgent situations. Want more details or examples?\n",
      "ChatCompletion(id='chatcmpl-Cz6834ITydCuh7WU87mjvzLSUl1Oc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Do you mean OpenAI? If so, it was founded in 2015 by Sam Altman, Greg Brockman, Ilya Sutskever, Wojciech Zaremba, John Schulman, and Elon Musk. Musk left the board in 2018. OpenAI later formed OpenAI LP with a capped-profit model; Altman is the CEO. If you meant something else, please clarify.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1768677603, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1118, prompt_tokens=29, total_tokens=1147, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1024, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "THIS THE NEXTLINE ==============\n",
      "Do you mean OpenAI? If so, it was founded in 2015 by Sam Altman, Greg Brockman, Ilya Sutskever, Wojciech Zaremba, John Schulman, and Elon Musk. Musk left the board in 2018. OpenAI later formed OpenAI LP with a capped-profit model; Altman is the CEO. If you meant something else, please clarify.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "def chat_with_ai(prompt: str) -> str:\n",
    "   \n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\", #\"gpt-5-turbo\", #\"gpt-5\", #\"gpt-5-mini\", #\"gpt-5-nano\"\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer the user's questions concisely.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "            # {\"role\": \"user\", \"content\": f\"Here is the context: \\n\\ {context} \\n\\. \\n\\n Now, answer the question: {prompt}\")\n",
    "        ]\n",
    "        )\n",
    "        print (response)\n",
    "        print(\"THIS THE NEXTLINE ==============\")\n",
    "        print (response.choices[0].message.content)\n",
    "\n",
    "\n",
    "user_input = input(\"PLease ask a question\")\n",
    "while True:\n",
    "    chat_with_ai(user_input)\n",
    "    user_input = input(\"PLease ask another question\")\n",
    "    if user_input.lower() == \"qw\":\n",
    "        print (\"Thanks for chatting with BOT\")\n",
    "        break  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
